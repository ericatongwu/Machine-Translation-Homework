# Machine-Translation-Homework
# Small Machine Translation homework just for fun

1.	Embedding algorithm: 
First, I use a function to code words into index. Then, I used nltk and Word2Vec model from gensim.models to get the embedding for each word.
2.	Input: Embedding vector for each sentence
Output: reversed order index which will generate the result. I have a standard answer written in target.txt
3.	Cost function: categorical_crossentropy
4.	Model: keras
5.	Parameters: layer numbers, nodes, epochs
6.	Overfitting: I tried to change the validation size.
7.	Error

## If I have more time, work on the machine learning model with other tools